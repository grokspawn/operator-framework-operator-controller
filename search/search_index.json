{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Why are we building OLM v1?","text":"<p>Operator Lifecycle Manager's mission has been to manage the lifecycle of cluster extensions centrally and declaratively on Kubernetes clusters. Its purpose has always been to make installing, running, and updating functional extensions to the cluster easy, safe, and reproducible for cluster administrators and PaaS administrators, throughout the lifecycle of the underlying cluster. </p> <p>OLM v0 was focused on providing unique support for these specific needs for a particular type of cluster extension, which have been coined as operators.  Operators are classified as one or more Kubernetes controllers, shipping with one or more API extensions (CustomResourceDefinitions) to provide additional functionality to the cluster. After running OLM v0 in production clusters for a number of years, it became apparent that there's an appetite to deviate from this coupling of CRDs and controllers, to encompass the lifecycling of extensions that are not just operators.</p> <p>OLM has been helping to define lifecycles for these extensions in which the extensions</p> <ul> <li>get installed, potentially causing other extensions to be installed as well as dependencies</li> <li>get customized with the help of customizable configuration at runtime </li> <li>get upgraded to newer version/s following upgrade paths defined by extension developers </li> <li>and finally, get decommissioned and removed.</li> </ul> <p>In the dependency model, extensions can rely on each other for required services that are out of scope of the primary purpose of an extension, allowing each extension to focus on a specific purpose. </p> <p>OLM also prevents conflicting extensions from running on the cluster, either with conflicting dependency constraints or conflicts in ownership of services provided via APIs. Since cluster extensions need to be supported with an enterprise-grade product lifecycle, there has been a growing need for allowing extension authors to limit installation and upgrade of their extension by specifying additional environmental constraints as dependencies, primarily to align with what was tested by the extension author's QE processes. In other words, there is an evergrowing ask for OLM to allow the author to enforce these support limitations in the form of additional constraints specified by extension authors in their packaging for OLM.</p> <p>During their lifecycle on the cluster, OLM also manages the permissions and capabilities extensions have on the cluster as well as the permission and access tenants on the cluster have to the extensions. This is done using the Kubernetes RBAC system, in combination with tenant isolation using Kubernetes namespaces. While the interaction surface of the extensions is solely composed of Kubernetes APIs the extensions define, there is an acute need to rethink the way tenant(i.e consumers of extensions) isolation is achieved. The ask from OLM, is to provide tenant isolation in a more intuitive way than is implemented in OLM v0</p> <p>OLM also defines a packaging model in which catalogs of extensions, usually containing the entire version history of each extension, are made available to clusters for cluster users to browse and select from. While these catalogs have so far been packaged and shipped as container images, there is a growing appetite to allow more ways of packaging and shipping these catalogs, besides also simplifying the building process of these catalogs, which so far have been very costly. The effort to bring down the cost was kicked off in OLM v0 with conversion of the underlying datastore for catalog metadata to File-based Catalogs, with more effort being invested to slim down the process in v1. Via new versions of extensions delivered with this new packaging system, OLM will be able to apply updates to existing running extensions on the cluster in a way where the integrity of the cluster is maintained and constraints and dependencies are kept satisfied.</p> <p>For a detailed writeup of OLM v1 requirements, please read the Product Requirements Documentation</p>"},{"location":"#the-olm-community","title":"The OLM community","text":"<p>The OLM v1 project is being tracked in a GitHub project</p> <p>You can reach out to the OLM community for feedbacks/discussions/contributions in the following channels:</p> <ul> <li>Kubernetes slack channel: #olm-dev</li> <li>Operator Framework on Google Groups</li> </ul>"},{"location":"components/","title":"Components","text":"<p>OLM v1 is composed of various component projects: </p> <ul> <li> <p>operator-controller: operator-controller is the central component of OLM v1, that consumes all of the components below to extend Kubernetes to allows users to install, and manage the lifecycle of other extensions</p> </li> <li> <p>rukpak: RukPak is a pluggable solution for the packaging and distribution of cloud-native content and supports advanced strategies for installation, updates, and policy. The project provides a content ecosystem for installing a variety of artifacts, such as Git repositories, Helm charts, OLM bundles, and more onto a Kubernetes cluster. These artifacts can then be managed, scaled, and upgraded in a safe way to enable powerful cluster extensions. At its core, RukPak is a small set of APIs, packaged as Kubernetes CustomResourceDefinitions, and controllers that watch for those APIs. These APIs express what content is being installed on-cluster and how to create a running deployment of the content.</p> </li> <li> <p>deppy: Deppy is a Kubernetes API that runs on- or off-cluster for resolving constraints over catalogs of RukPak bundles. Deppy is part of the next iteration of OLM and was first introduced here. The initial goal of the project is to remove the dependency manager from the Operator Lifecycle Manager (OLM) and make it its own generic component.</p> </li> <li> <p>catalogD: Catalogd is a Kubernetes extension that unpacks file-based catalog (FBC) content that is packaged and shipped in container images, for consumption by clients on-clusters (unpacking from other sources, like git repos, OCI artifacts etc, are in the roadmap for catalogD). As component of the Operator Lifecycle Manager (OLM) v1 microservices architecture, catalogD hosts metadata for Kubernetes extensions packaged by the authors of the extensions, as a result helping customers discover installable content.</p> </li> </ul>"},{"location":"olmv1_roadmap/","title":"OLM v1 roadmap","text":""},{"location":"olmv1_roadmap/#functional-requirements","title":"Functional Requirements","text":"<p>Priority Rating: 1 highest, 2 medium, 3 lower (e.g. P2 = Medium Priority)</p>"},{"location":"olmv1_roadmap/#f1-extension-catalogs-p1","title":"F1 - Extension catalogs (P1)","text":"<p>The existing OLM concepts around catalogs, packages and channels is to be used as a basis for below functional requirements.</p>"},{"location":"olmv1_roadmap/#f2-extension-catalog-discovery-p2","title":"F2 - Extension catalog discovery (P2)","text":"<p>Unprivileged tenants need to have the ability to discover extensions that are available to install. In particular users need to be able to discover all versions in all channels that an extension package defines in a catalog. The privilege should be given at the discretion of the cluster administrator.</p>"},{"location":"olmv1_roadmap/#f3-dependency-preview-p3","title":"F3 - Dependency preview (P3)","text":"<p>Before extension installation, OLM needs to introspect the dependencies of an extension and present a preview of the resolution result to the user to let the user confirm they are ok with this.</p>"},{"location":"olmv1_roadmap/#f4-dependency-review-p3","title":"F4 - Dependency review (P3)","text":"<p>For installed extensions OLM needs to surface the dependency relationship to other installed extensions and also highlight which other extensions depend on a particular extension so users are informed about the relationships at runtime.</p>"},{"location":"olmv1_roadmap/#f5-permission-preview-p2","title":"F5 - Permission preview (P2)","text":"<p>Before extension installation and updates, OLM needs to allow introspection of the permissions the extension requires on cluster and dependencies APIs. This is especially important during updates when the permission scope increases in which case updates should be blocked until approved (F14).</p>"},{"location":"olmv1_roadmap/#f6-installupdate-preflight-checks-p1","title":"F6 - Install/Update preflight checks (P1)","text":"<p>When installing and updating extensions OLM should carry out a set of preflight checks to prevent installations from going into a failed state as a result of attempting an upgrade or install. Preflight checks should include availability and (if applicable) health of (running) dependencies and any cluster runtime constraints (F19).</p>"},{"location":"olmv1_roadmap/#f7-extension-installation-p1","title":"F7 - Extension installation (P1)","text":"<p>OLM needs a declarative way to install extensions either from a catalog of extensions or directly from an OCI image. Should the installation attempt fail due to unfilled requirements, constraints, preflight checks or dependencies there needs to be an option to force the install. Extensions are cluster-wide singletons, thus they can only be installed once in the cluster and are managed at cluster-scope.</p>"},{"location":"olmv1_roadmap/#f8-semver-based-update-policy-p2","title":"F8 - Semver-based update policy (P2)","text":"<p>OLM should allow users to specify if and when extensions are updated. Manual update policy should include the user explicitly approving an update to be installed. An automatic update policy should allow updates to automatically be applied as soon as they are available and should provide further conditions upon which an update is to be applied. Conditions concern version changes of the extension, specifically: automatic updates on z-streams only, automatic updates on y-streams only, always automatic update. Updates across channels are outside of the update policy.</p>"},{"location":"olmv1_roadmap/#f9-update-notification-p3","title":"F9 - Update notification (P3)","text":"<p>As updates can be made available at any time using OLMs existing over-the-air catalog update capabilities, OLM should provide events / notifications on the platform to notify users about available but not yet approved updates of existing installed extensions, specifically so that graphical consoles can pick them up and visualize them. Automatically applied updates as per F8 should also create notifications.</p>"},{"location":"olmv1_roadmap/#f10-extension-updates-p2","title":"F10 - Extension updates (P2)","text":"<p>As extensions get updated, either automatically or manually, OLM replaces the older version of the extensions with a newer version atomically. Up until any custom code or conversion logic runs, an update should be able to be rolled back (F23). When multiple extensions are updated to satisfy an update request, the update policy of each extension needs to be respected to allow users to pin certain extensions to installed versions or certain types of updates (e.g. z-stream only). It should also be possible to force an update to a certain version, even if there is no direct path as per the graph metadata. Otherwise all versions along the update path should be allowed for selecting by the user as the desired target version.Otherwise all versions on</p>"},{"location":"olmv1_roadmap/#f11-request-approval-flow-for-installs-updates-p2","title":"F11 - Request / Approval Flow for Installs / Updates (P2)","text":"<p>To support multi-tenant environments a request / approval flow is desirable for generally available content within default catalogs. In this model any tenant with enough privilege can discover installable content and can trigger an install request, which can in turn be approved or denied by a more privileged administrative role. Such requests should also have timeouts. Administrators should have the ability to define a list of extensions that are automatically approved at the scope of a namespace. Administrators should be able to get aware of unapproved requested via alerts triggered by the platform.</p>"},{"location":"olmv1_roadmap/#f12-installed-extension-discovery-p1","title":"F12 - Installed extension discovery (P1)","text":"<p>Unprivileged tenants need to be able to discover installed extensions if they are offering services for them to use in their namespace. OLM needs to provide distinct controls for installed extensions which administrators can use to regulate in which namespaces extensions are discoverable by tenants, irrespective of the namespaces in which the extension has permissions on cluster APIs (see F13)</p>"},{"location":"olmv1_roadmap/#f13-extension-permissions-management-p1","title":"F13 - Extension permissions management (P1)","text":"<p>Administrative personas need to be able to configure in which namespaces in the cluster the extension can get the requested permissions the extension author deems required. The control needs to be independent of the controls in F12. Extensions should always be given permissions to update their own APIs (if they define any) to inform users about potential lack of permissions in their namespace.</p>"},{"location":"olmv1_roadmap/#f14-extension-permissions-escalation-checks-p2","title":"F14 - Extension permissions escalation checks (P2)","text":"<p>If, in the course of an update, an extension requests more permissions than the currently installed version, an automatic update is blocked and an administrative persona needs to specifically approve the update by default. The user who installed the extension can opt out of these permission increase checks for the purpose of automation.</p>"},{"location":"olmv1_roadmap/#f15-selective-extension-permissions-grants-p3","title":"F15 - Selective extension permissions grants (P3)","text":"<p>Administrative personas can choose to give extensions only a subset of the permissions it requests. This should be manageable at a per namespace level.</p>"},{"location":"olmv1_roadmap/#f16-extension-removal-p1","title":"F16 - Extension removal (P1)","text":"<p>Administrative personas need to be able to remove an extension including all the content that was part of the original installation bundle. Special handling should be implemented for CRDs, which when not removed, are left behind in a functioning state (i.e.any dependencies on running controllers like conversion webhooks need to be removed). When they are to be removed this can only happen if the user opts into F17. Special care also needs to be taken to allow the extension to perform any clean upon getting a signal to be removed. Components need to be removed in an order that allows the extension to handle a graceful shutdown.</p>"},{"location":"olmv1_roadmap/#f17-extension-cascading-removal-p2","title":"F17 - Extension cascading removal (P2)","text":"<p>OLM needs to be able to cleanly remove an extension entirely, which means deleting CRDs and other resources on the cluster. In particular this means the removal of all custom resource instances of the CRDs to be deleted and all extensions with a hard dependency. A user needs to actively opt-in to this behavior and OLM has to sequence the successful removal of all affected components and the extension itself.</p>"},{"location":"olmv1_roadmap/#f18-standalone-extension-bundle-installation-p2","title":"F18 - Standalone extension bundle installation (P2)","text":"<p>For local development OLM should allow the installation of an extension by directly referring to the bundle / OCI image in a container registry rather than a package name of an extension in a catalog containing the image in order to simplify testing and delivering hotfixes.</p>"},{"location":"olmv1_roadmap/#f19-extension-constraints-p1","title":"F19 - Extension constraints (P1)","text":"<p>OLM needs to allow extensions to specify constraints towards aspects of the running cluster and other currently installed or future extensions. Aspects of the running cluster should include software version, resource utilization, overall resource availability and state of configuration settings. These constraints need to be evaluated when extensions are attempted to be installed or updated.</p>"},{"location":"olmv1_roadmap/#f20-extension-health-p1","title":"F20 - Extension health (P1)","text":"<p>OLM needs to be able to report the overall health state of the extension on a cluster along the following set of aspects: presence of all required objects from the extension bundle, health of all components that have a liveness / readiness endpoint, presence and health of all other extensions the extension in question has a dependency on as well as evaluation of all additional constraints from F19. An extension that was forced to install despite missing / unhealthy dependencies and violated constraints has a reduced health scope down to the liveness / readiness endpoint.</p>"},{"location":"olmv1_roadmap/#f21-custom-extension-health-p3","title":"F21 - Custom extension health (P3)","text":"<p>OLM should provide a way for extensions to report an aggregate health state with custom logic. This should align with other communications channels that are also used for extensions to declare update readiness (F25). This way extensions can report health more accurately than what OLM reports today based on simple readiness of the extension controller pod. Clients like graphical consoles should be able to make use of this to supply additional overall health states of extensions that provide some form of control plane by the user of other extensions.</p>"},{"location":"olmv1_roadmap/#f22-best-effort-resolution-p2","title":"F22 - Best effort resolution (P2)","text":"<p>OLM should always try its best to resolve installation and update requests with the currently available and healthy set catalogs to resolve against. Intermittently or permanently failed catalogs should not block resolution for installation and updates. Fulfilling user requests is valued higher than determinism of results.</p>"},{"location":"olmv1_roadmap/#f23-opt-in-to-fallback-rollback-p2","title":"F23 - Opt-in to fallback / rollback (P2)","text":"<p>OLM should allow extension developers to specify whether or not it is safe to rollback from a particular current version of the extension to an author-specified previous version, once an extension update has passed pre-flights checks in F10 but subsequently failed to become available or carry out a migration. In these cases OLM should allow the administrator to downgrade the extension to the specific previous version. OLM should also respect this downgrade path when conducting updates that fail and use it to fail back to the previous version of the extension indicating that the downgrade path is supported. Extension uptime is an important goal of OLM.</p>"},{"location":"olmv1_roadmap/#f24-extension-overrides-p2","title":"F24 - Extension Overrides (P2)","text":"<p>Components deployed as part of extensions will require user-provided modifications at runtime in order to aid features like placement, networking configuration, proxy configuration etc. that require customization of volume mounts, annotations, labels, environment variables, taints, tolerations, node selectors, affinity, and resources. OLM should support accepting these customizations to the extension as input from the user prior or after the installation of an extension and apply them to applicable objects such as Deployments, StatefulSets, ReplicatSets.</p>"},{"location":"olmv1_roadmap/#f25-extension-controlled-update-readiness-p2","title":"F25 - Extension-controlled Update Readiness (P2)","text":"<p>Extensions should be able to control their readiness for updates. An extension could be on a critical path or in a state where updates would lead to disruption or worst-case: outages. OLM should respect these update readiness signals and allow the extension to signal readiness differentiated to what nature the update is based on semantic versioning rules, i.e. patch updates vs. minor or major updates. Once the signal is encountered, OLM should block the update until the signal disappears.</p>"},{"location":"olmv1_roadmap/#f26-canary-style-rollouts-p3","title":"F26 - Canary Style Rollouts (P3)","text":"<p>OLM should have an opinion about how administrators can carry out roll outs of new extension versions that coexist with already installed versions of the extension, in particular if the extension only ships a controller. While conflicting CRDs cannot co-exist, controllers that only selectively reconcile objects (Ingress controller pattern) can. OLM should support these deployment styles while ensuring integrity of cluster-level extensions like CRDs.</p>"},{"location":"olmv1_roadmap/#f27-pluggable-certificate-management-p2","title":"F27 - Pluggable certificate management (P2)","text":"<p>OLM should rely on other controllers to create and lifecycle TLS certificates required to drive the functionality of certain extensions, like webhooks that need to trust /  need to be trusted by the cluster's API server. OLM should not implement any certificate handling itself. In a first implementation support should be established for cert-manager.</p>"},{"location":"olmv1_roadmap/#f28-provided-service-versions-p2","title":"F28 - Provided service versions (P2)","text":"<p>Workload-based extensions can offer multiple services (a.k.a. operands) and their respective versions. Extension admins need to see which operand versions each extension supports by the extension version. Extension admins are guaranteed to install or upgrade an extension that supports their desired operand version(s). Extension authors can list supported operand versions and have guarantees that they can list dependencies that support the necessary operand version(s). When mirroring a catalog, mirroring users can select a subset of the related images to mirror, based on desired operand version(s).</p>"},{"location":"olmv1_roadmap/#behavioral-requirements","title":"Behavioral Requirements","text":"<p>Priority Rating: 1 highest, 2 medium, 3 lower (ex. P2 = Medium Priority)</p>"},{"location":"olmv1_roadmap/#b1-single-api-control-surface-p1","title":"B1 - Single API control surface (P1)","text":"<p>While the underlying implementation of the functional requirements can be carried out by different controllers with different APIs, to the administrative and non-administrative users there should be a single, cluster-level API that represents an installed extension with all high level controls described in / required by F4, F7, F8, F10, F13, F14, F15, F16, F17, F18, F21, F22, F23 and F24.</p>"},{"location":"olmv1_roadmap/#b2-gitops-friendly-api-surface-p1","title":"B2 - GitOps-friendly API surface (P1)","text":"<p>In many cases OLM APIs will not be used by a human via a CLI or GUI interactively but declaratively through a GitOps pipeline. This means the primary OLM API to lifecycle an extension cannot leak abstractions to other APIs for initial deployment or reconfiguration. Modifications must not require conditional lookup or modifications of other objects on the cluster that are created as part of the declarative intent stored in git in the form of YAML manifest files.</p>"},{"location":"olmv1_roadmap/#b3-declarative-api-p1","title":"B3 - Declarative API (P1)","text":"<p>As an extension itself, OLMs API controls have to allow for operations to be carried out solely declaratively. This mandates continuous reconciliation and eventual consistency of desired state. OLM should not conduct one-off operations. OLM should not require either clean up of failed operations or restating intent to retry a failed operation (with the exception of F11).</p>"},{"location":"olmv1_roadmap/#b4-event-trail-p2","title":"B4 - Event trail (P2)","text":"<p>OLM should make heavy use of Kubernetes events to leave an audit trail of tasks and actions carried out on the cluster. For expected failure scenarios administrators should not need to consult the OLM controller logs for debugging but solely rely on events and status conditions (see also B6).</p>"},{"location":"olmv1_roadmap/#b5-force-overrides-p1","title":"B5 - Force overrides (P1)","text":"<p>While OLM has a lot of opinions about safe operations with cluster extensions they do not apply all the time since OLM cannot possibly foresee how extensions behave at runtime. It needs to yield to the user in cases where they have more certainty about what's going to happen based on their background knowledge of the cluster or the extension. It should offer ways to force-override decisions that OLM made that block the user from proceeding in a certain direction, especially in the areas of extension installation, removal and updates.</p>"},{"location":"olmv1_roadmap/#b6-human-readable-status-extensions-information-p2","title":"B6 - Human-readable status extensions information (P2)","text":"<p>Whenever OLM is in the process of or having reached or failed to reach a desired state it needs to update the user about what is happening / what has happened without assuming knowledge about OLM internal or implementation details.</p>"},{"location":"olmv1_roadmap/#b7-scalability-resource-consumption-p1","title":"B7 - Scalability &amp; Resource consumption (P1)","text":"<p>OLM is used on clusters with hundreds to thousands of namespaces and tenants. Its API controls, specifically for F2 and F12 need to be built in such a way that resource consumption scales linearly with usage and cluster size and the overall resource usage envelope stays within manageable bounds that does not put the cluster stability, especially that of the API server at risk. System memory especially is a scarce resource.</p>"},{"location":"olmv1_roadmap/#compatibility-requirements","title":"Compatibility Requirements:","text":""},{"location":"olmv1_roadmap/#c1-compatibility-with-existing-extensions-p1","title":"C1 - Compatibility with existing extensions  (P1)","text":"<p>OLM should be able to manage extensions packaged with the current bundle format in the way described by the functional and behavior requirements when the bundle supports AllNamespace installation mode.</p>"},{"location":"olmv1_roadmap/#c2-compatibility-with-existing-catalogs-p1","title":"C2 - Compatibility with existing catalogs (P1)","text":"<p>OLM should be able to retrieve and update extensions that adhere to C1 from the currently supported catalog formats (File-based catalogs).</p>"},{"location":"olmv1_roadmap/#c3-incompatibility-with-existing-extensions-p1","title":"C3 - Incompatibility with existing extensions (P1)","text":"<p>OLM 1.0 does not support managing bundles or extension versions that do not support AllNamespace installation mode with the new set of APIs or flows</p>"},{"location":"olmv1_roadmap/#assumptions","title":"Assumptions","text":"<ul> <li> <p>No additional tenancy model will be introduced at the control plane / API layer of Kubernetes upstream</p> </li> <li> <p>kcp doesn\u2019t fundamentally change OLMs role and responsibilities around managing extensions (at least initially)</p> </li> <li> <p>OLM will move to a descoped, cluster-wide singleton model for cluster extensions, extension management isn\u2019t namespaced</p> </li> </ul>"},{"location":"olmv1_roadmap/#constraints","title":"Constraints","text":"<ul> <li>Only extension bundles with \u201cAllNamespace\u201d mode installation support can be lifecycled with the new APIs / flows in OLM 1.0</li> </ul>"},{"location":"olmv1_roadmap/#dependencies","title":"Dependencies","text":"<ul> <li>\"F13 - Extension permissions management (P1)\" and \"F12 - Installed extension discovery (P1)\" will land prior to the GA of OLM 1.0 to unblock most extensions that do not support AllNamespace installation mode today.</li> </ul>"},{"location":"olmv1_roadmap/#migration","title":"Migration","text":"<ul> <li> <p>A new set of APIs is introduced in parallel to the existing set of APIs</p> </li> <li> <p>Users opt-in to the new set of APIs, potentially resulting in a reinstall of their extension if required</p> </li> <li> <p>Extensions that are shipped with the current bundle format with AllNamespace mode can simply be reused with the new set of APIs and controls</p> </li> <li> <p>Extensions that do not support AllNamespace mode cannot be managed with the new APIs</p> </li> <li> <p>Migration scripting is provided to mass-convert existing installed extensions (\u201cSubscription\u201d / \u201cOperatorGroup\u201d objects) on existing clusters to the new OLM 1.0 model assuming they are compatible</p> </li> <li> <p>Extension authors that are also SRE/Managed PaaS administrators are incentivized to make their extension compatible with the requirements of OLM 1.0 to reap the operational benefits</p> </li> </ul>"},{"location":"olmv1_roadmap/#todo","title":"TODO","text":"<ul> <li>Definition of \"extension\"</li> <li>Does OLM become ELM?  Does this provide of provisioning bundles that do not add APIs?</li> </ul>"},{"location":"Tasks/adding-a-catalog/","title":"Adding a catalog of extensions to a cluster","text":"<p>Extension authors can publish their products in catalogs. Catalogs are curated collections of Kubernetes extensions, such as Operators. Cluster administrators can add these catalogs to their cluster. Cluster administrators can enable polling to get over-the-air updates to catalogs when extension authors publish changes such as bug fixes and new features.</p> <p>For example, the Kubernetes community Operators catalog is a catalog of curated extensions that is developed by the Kubernetes community. You can see the available extensions at Operatorhub.io. This catalog is distributed as an image quay.io/operatorhubio/catalog that can be installed on clusters.</p>"},{"location":"Tasks/adding-a-catalog/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to a Kubernetes cluster, for example <code>kind</code>, using an account with <code>cluster-admin</code> permissions</li> <li>Operator Controller installed on the cluster</li> <li>Catalogd installed on the cluster</li> <li>Kubernetes CLI (<code>kubectl</code>) installed on your workstation</li> </ul>"},{"location":"Tasks/adding-a-catalog/#procedure","title":"Procedure","text":"<ol> <li> <p>Create a catalog custom resource (CR):</p> catalog_cr.yaml<pre><code>apiVersion: catalogd.operatorframework.io/v1alpha1\nkind: Catalog\nmetadata:\n  name: operatorhubio\nspec:\n  source:\n    type: image\n    image:\n      ref: &lt;catalog_image&gt;\n      pollInterval: &lt;poll_interval_duration&gt;\n</code></pre> <code>catalog_name</code> Specifies the image reference for the catalog you want to install, such as <code>quay.io/operatorhubio/catalog:latest</code>. <code>poll_interval_duration</code> Specifies the interval for polling the remote registry for newer image digests.     The default value is <code>24h</code>.     Valid units include seconds (<code>s</code>), minutes (<code>m</code>), and hours (<code>h</code>).     To disable polling, set a zero value, such as <code>0s</code>. Example `operatorhubio.yaml` CR<pre><code>apiVersion: catalogd.operatorframework.io/v1alpha1\nkind: Catalog\nmetadata:\n  name: operatorhub\nspec:\n  source:\n    type: image\n    image:\n      ref: quay.io/operatorhubio/catalog:latest\n      pollInterval: 1h\n</code></pre> </li> <li> <p>Apply the catalog CR:</p> <pre><code>$ kubectl apply -f &lt;catalog_cr&gt;.yaml\n</code></pre> Example output<pre><code>catalog.catalogd.operatorframework.io/redhat-operators created\n</code></pre> </li> </ol>"},{"location":"Tasks/adding-a-catalog/#verification","title":"Verification","text":"<ul> <li> <p>Run the following commands to verify the status of your catalog:</p> <ul> <li> <p>Check if your catalog is available on the cluster:</p> <pre><code>$ kubectl get catalog\n</code></pre> Example output<pre><code>NAME            PHASE   AGE\noperatorhubio           9s\n</code></pre> </li> <li> <p>Check the status of your catalog:</p> <pre><code>$ kubectl describe catalog\n</code></pre> Example output<pre><code>Name:         operatorhubio\nNamespace:\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nAPI Version:  catalogd.operatorframework.io/v1alpha1\nKind:         Catalog\nMetadata:\n  Creation Timestamp:  2024-03-12T19:34:50Z\n  Finalizers:\n    catalogd.operatorframework.io/delete-server-cache\n  Generation:        2\n  Resource Version:  6469\n  UID:               2e2778cb-dda6-4645-96b7-992e8dd37503\nSpec:\n  Source:\n    Image:\n      Poll Interval:  15m0s\n      Ref:            quay.io/operatorhubio/catalog:latest\n    Type:             image\nStatus:\n  Conditions:\n    Last Transition Time:  2024-03-12T19:35:34Z\n    Message:\n    Reason:                UnpackSuccessful\n    Status:                True\n    Type:                  Unpacked\n  Content URL:             http://catalogd-catalogserver.catalogd-system.svc/catalogs/operatorhubio/all.json\n  Observed Generation:     2\n  Phase:                   Unpacked\n  Resolved Source:\n    Image:\n      Last Poll Attempt:  2024-03-12T19:35:26Z\n      Ref:                quay.io/operatorhubio/catalog:latest\n      Resolved Ref:       quay.io/operatorhubio/catalog@sha256:dee29aaed76fd1c72b654b9bc8bebc4b48b34fd8d41ece880524dc0c3c1c55ec\n    Type:                 image\nEvents:                   &lt;none&gt;\n</code></pre> </li> </ul> </li> </ul>"},{"location":"Tasks/explore-available-packages/","title":"Finding extensions to install","text":"<p>After you add a catalog of exetensions to your cluster, you must port forward your catalog as a service. Then you can query the catalog by using <code>curl</code> commands and the <code>jq</code> CLI tool to find extensions to install.</p>"},{"location":"Tasks/explore-available-packages/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have added a catalog of extensions, such as OperatorHub.io, to your cluster.</li> <li>You have installed the <code>jq</code> CLI tool.</li> </ul>"},{"location":"Tasks/explore-available-packages/#procedure","title":"Procedure","text":"<ol> <li> <p>Port forward the catalog server sevice:</p> <pre><code>$ kubectl -n catalogd-system port-forward svc/catalogd-catalogserver 8080:80\n</code></pre> </li> <li> <p>Return a list of all the extensions in a catalog:     <pre><code>$ curl http://localhost:8080/catalogs/operatorhubio/all.json | jq -s '.[] | select(.schema == \"olm.package\") | .name'\n</code></pre></p> Success Example output<pre><code>\"ack-acm-controller\"\n\"ack-acmpca-controller\"\n\"ack-apigatewayv2-controller\"\n\"ack-applicationautoscaling-controller\"\n\"ack-cloudfront-controller\"\n\"ack-cloudtrail-controller\"\n\"ack-cloudwatch-controller\"\n\"ack-cloudwatchlogs-controller\"\n\"ack-dynamodb-controller\"\n\"ack-ec2-controller\"\n\"ack-ecr-controller\"\n\"ack-ecs-controller\"\n\"ack-efs-controller\"\n\"ack-eks-controller\"\n\"ack-elasticache-controller\"\n\"ack-emrcontainers-controller\"\n\"ack-eventbridge-controller\"\n\"ack-iam-controller\"\n\"ack-kafka-controller\"\n\"ack-keyspaces-controller\"\n\"ack-kinesis-controller\"\n\"ack-kms-controller\"\n\"ack-lambda-controller\"\n\"ack-memorydb-controller\"\n\"ack-mq-controller\"\n\"ack-networkfirewall-controller\"\n\"ack-opensearchservice-controller\"\n\"ack-pipes-controller\"\n\"ack-prometheusservice-controller\"\n\"ack-rds-controller\"\n\"ack-route53-controller\"\n\"ack-route53resolver-controller\"\n\"ack-s3-controller\"\n\"ack-sagemaker-controller\"\n\"ack-secretsmanager-controller\"\n\"ack-sfn-controller\"\n\"ack-sns-controller\"\n\"ack-sqs-controller\"\n\"aerospike-kubernetes-operator\"\n\"airflow-helm-operator\"\n\"aiven-operator\"\n\"akka-cluster-operator\"\n\"alvearie-imaging-ingestion\"\n\"anchore-engine\"\n\"apch-operator\"\n\"api-operator\"\n\"api-testing-operator\"\n\"apicast-community-operator\"\n\"apicurio-registry\"\n\"apimatic-kubernetes-operator\"\n\"app-director-operator\"\n\"appdynamics-operator\"\n\"application-services-metering-operator\"\n\"appranix\"\n\"aqua\"\n\"argocd-operator\"\n...\n</code></pre> <p>Important</p> <p>Currently, OLM 1.0 does not support the installation of extensions that use webhooks or that target a single or specified set of namespaces.</p> <ul> <li> <p>Return list of packages that support <code>AllNamespaces</code> install mode and do not use webhooks:</p> <pre><code>$ curl http://localhost:8080/catalogs/operatorhubio/all.json | jq -c 'select(.schema == \"olm.bundle\") | {\"package\":.package, \"version\":.properties[] | select(.type == \"olm.bundle.object\").value.data | @base64d | fromjson | select(.kind == \"ClusterServiceVersion\" and (.spec.installModes[] | select(.type == \"AllNamespaces\" and .supported == true) != null) and .spec.webhookdefinitions == null).spec.version}'\n</code></pre> Success Example output<pre><code>{\"package\":\"ack-acm-controller\",\"version\":\"0.0.12\"}\n{\"package\":\"ack-acmpca-controller\",\"version\":\"0.0.5\"}\n{\"package\":\"ack-apigatewayv2-controller\",\"version\":\"1.0.7\"}\n{\"package\":\"ack-applicationautoscaling-controller\",\"version\":\"1.0.11\"}\n{\"package\":\"ack-cloudfront-controller\",\"version\":\"0.0.9\"}\n{\"package\":\"ack-cloudtrail-controller\",\"version\":\"1.0.8\"}\n{\"package\":\"ack-cloudwatch-controller\",\"version\":\"0.0.3\"}\n{\"package\":\"ack-cloudwatchlogs-controller\",\"version\":\"0.0.4\"}\n{\"package\":\"ack-dynamodb-controller\",\"version\":\"1.2.9\"}\n{\"package\":\"ack-ec2-controller\",\"version\":\"1.2.4\"}\n{\"package\":\"ack-ecr-controller\",\"version\":\"1.0.12\"}\n{\"package\":\"ack-ecs-controller\",\"version\":\"0.0.4\"}\n{\"package\":\"ack-efs-controller\",\"version\":\"0.0.5\"}\n{\"package\":\"ack-eks-controller\",\"version\":\"1.3.3\"}\n{\"package\":\"ack-elasticache-controller\",\"version\":\"0.0.29\"}\n{\"package\":\"ack-emrcontainers-controller\",\"version\":\"1.0.8\"}\n{\"package\":\"ack-eventbridge-controller\",\"version\":\"1.0.6\"}\n{\"package\":\"ack-iam-controller\",\"version\":\"1.3.6\"}\n{\"package\":\"ack-kafka-controller\",\"version\":\"0.0.4\"}\n{\"package\":\"ack-keyspaces-controller\",\"version\":\"0.0.11\"}\n...\n</code></pre> </li> </ul> </li> <li> <p>Inspect the contents of an extension's metadata:</p> <pre><code>$ curl http://localhost:8080/catalogs/operatorhubio/all.json | jq -s '.[] | select( .schema == \"olm.package\") | select( .name == \"&lt;package_name&gt;\")'\n</code></pre> <code>package_name</code> Specifies the name of the package you want to inspect. Success Example output<pre><code>{\n  \"defaultChannel\": \"stable-v6.x\",\n  \"icon\": {\n    \"base64data\": \"PHN2ZyB4bWxucz0ia...\n    \"mediatype\": \"image/svg+xml\"\n  },\n  \"name\": \"cockroachdb\",\n  \"schema\": \"olm.package\"\n}\n</code></pre> </li> </ol>"},{"location":"Tasks/explore-available-packages/#additional-resources","title":"Additional resources","text":"<ul> <li>Catalog queries</li> </ul>"},{"location":"Tasks/installing-an-extension/","title":"Installing an extension from a catalog","text":"<p>In Operator Lifecycle Manager (OLM) 1.0, Kubernetes extensions are scoped to the cluster. After you add a catalog to your cluster, you can install an extension by creating a custom resource (CR) and applying it.</p> <p>Important</p> <p>Currently, extensions that use webhooks or target a single or specified set of namespaces cannot be installed. Extensions must not include webhooks and must use the <code>AllNamespaces</code> install mode.</p>"},{"location":"Tasks/installing-an-extension/#prerequisites","title":"Prerequisites","text":"<ul> <li>The <code>jq</code> CLI tool is installed.</li> <li>You have added a catalog to your cluster.</li> </ul>"},{"location":"Tasks/installing-an-extension/#procedure","title":"Procedure","text":"<ol> <li> <p>Create a CR for the Kubernetes extension you want to install:</p> Example CR<pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  name: &lt;extension_name&gt;\nspec:\n  packageName: &lt;package_name&gt;\n  channel: &lt;channel&gt;\n  version: \"&lt;version&gt;\"\n</code></pre> <code>extension_name</code> Specifies a custom name for the Kubernetes extension you want to install, such as <code>my-camel-k</code>. <code>package_name</code> Specifies the name of the package you want to install, such as <code>camel-k</code>. <code>channel</code> Optional: Specifies the extension's channel, such as <code>stable</code> or <code>candidate</code>. <code>version</code> Optional: Specifies the version or version range you want installed, such as <code>1.3.1</code> or <code>\"&lt;2\"</code>.  If you use a comparison string to define a version range, the string must be surrounded by double quotes (<code>\"</code>). <p>Warning</p> <p>Currently, the following limitations affect the installation of extensions:</p> <ul> <li>If mulitple catalogs are added to a cluster, you cannot specify a catalog when you install an extension.</li> <li>OLM 1.0 requires that all of the extensions have unique bundle and package names for dependency resolution.</li> </ul> <p>As a result, if two catalogs have an extension with the same name, the installation might fail or lead to an unintended outcome. For example, the first extension that matches might install successfully and finish without searching for a match in the second catalog.</p> </li> <li> <p>Apply the CR to the cluster:</p> <pre><code>$ kubectl apply -f &lt;cr_name&gt;.yaml\n</code></pre> Success Example output<pre><code>clusterextension.olm.operatorframework.io/camel-k created\n</code></pre> </li> </ol>"},{"location":"Tasks/installing-an-extension/#verification","title":"Verification","text":"<ul> <li> <p>Describe the installed extension:</p> <pre><code>$ kubectl describe clusterextensions\n</code></pre> Success Example output<pre><code>Name:         my-camel-k\nNamespace:\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nAPI Version:  olm.operatorframework.io/v1alpha1\nKind:         ClusterExtension\nMetadata:\n  Creation Timestamp:  2024-03-15T15:03:47Z\n  Generation:          1\n  Resource Version:    7691\n  UID:                 d756879f-217d-4ebe-85b1-8427bbb2f1df\nSpec:\n  Package Name:               camel-k\n  Upgrade Constraint Policy:  Enforce\nStatus:\n  Conditions:\n    Last Transition Time:     2024-03-15T15:03:50Z\n    Message:                  resolved to \"quay.io/operatorhubio/camel-k@sha256:d2b74c43ec8f9294450c9dcf2057be328d0998bb924ad036db489af79d1b39c3\"\n    Observed Generation:      1\n    Reason:                   Success\n    Status:                   True\n    Type:                     Resolved\n    Last Transition Time:     2024-03-15T15:04:13Z\n    Message:                  installed from \"quay.io/operatorhubio/camel-k@sha256:d2b74c43ec8f9294450c9dcf2057be328d0998bb924ad036db489af79d1b39c3\"\n    Observed Generation:      1\n    Reason:                   Success\n    Status:                   True\n    Type:                     Installed\n  Installed Bundle Resource:  quay.io/operatorhubio/camel-k@sha256:d2b74c43ec8f9294450c9dcf2057be328d0998bb924ad036db489af79d1b39c3\n  Resolved Bundle Resource:   quay.io/operatorhubio/camel-k@sha256:d2b74c43ec8f9294450c9dcf2057be328d0998bb924ad036db489af79d1b39c3\nEvents:                       &lt;none&gt;\n</code></pre> </li> </ul>"},{"location":"Tasks/uninstall-an-extension/","title":"Deleting an extension","text":"<p>You can uninstall a Kubernetes extension and its associated custom resource definitions (CRD) by deleting the extension's custom resource (CR).</p>"},{"location":"Tasks/uninstall-an-extension/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have an extension installed.</li> </ul>"},{"location":"Tasks/uninstall-an-extension/#procedure","title":"Procedure","text":"<ul> <li> <p>Delete the extension's CR:</p> <pre><code>$ kubectl delete clusterextensions &lt;extension_name&gt;\n</code></pre> <code>extension_name</code> Specifies the name defined in the <code>metadata.name</code> field of the extension's CR. Example output<pre><code>clusterextension.olm.operatorframework.io \"argocd-operator\" deleted\n</code></pre> </li> </ul>"},{"location":"Tasks/uninstall-an-extension/#verification","title":"Verification","text":"<ul> <li> <p>Verify that the Kubernetes extension is deleted:</p> <pre><code>$ kubectl get clusterextension.olm.operatorframework.io\n</code></pre> Example output<pre><code>No resources found\n</code></pre> </li> </ul>"},{"location":"demos/coast-to-coast-q4-2023/","title":"Coast-to-coast Demo for Q4 2023","text":"<p>This coast-to-coast demo highlights some of the new features introduced to OLMv1 in Q4 of 2023.</p> <p>New Features: - <code>Catalog</code> polling - Version range support on the <code>spec.version</code> field for <code>ClusterExtension</code> resources - Semver upgrade constraint policy - <code>BundleDeployment</code> health status</p> <p>This document will go through an example that highlights each of these new features. Each step will be documented as if you are following along and will be done sequentially. This document will also use some values specific to this example and in your own projects should be replaced to use a different value.</p>"},{"location":"demos/coast-to-coast-q4-2023/#prerequisites","title":"Prerequisites","text":"<ul> <li>A running Kubernetes cluster where you have admin privileges</li> <li><code>operator-sdk</code> installed<ul> <li>Installation instructions can be found at https://sdk.operatorframework.io/docs/installation/</li> </ul> </li> <li><code>kubectl</code> installed<ul> <li>Installation instructions can be found at https://kubernetes.io/docs/tasks/tools/</li> </ul> </li> <li>A container runtime of your choice, in this demo we will be using <code>docker</code></li> <li>Install <code>operator-controller</code> v0.8.0 <ul> <li>Installation instructions can be found at https://github.com/operator-framework/operator-controller/releases/tag/v0.8.0</li> </ul> </li> <li><code>kustomize</code> installed<ul> <li>Installation instructions can be found at https://kubectl.docs.kubernetes.io/installation/kustomize/</li> </ul> </li> <li><code>yq</code> installed<ul> <li>Installation instructions can be found at https://github.com/mikefarah/yq/#install</li> </ul> </li> </ul>"},{"location":"demos/coast-to-coast-q4-2023/#prepare-for-takeoff","title":"Prepare for takeoff","text":"<p>Before we can start exploring the new features we need to do some preparation by creating a new extension and building a few different versions.</p>"},{"location":"demos/coast-to-coast-q4-2023/#create-an-extension","title":"Create an extension","text":"<p>[!NOTE] In this demo, we aren't going to make the extension do anything.</p> <p>We will create a new extension using the <code>operator-sdk</code>.</p> <ul> <li> <p>Create a new directory for the project and <code>cd</code> into it: <pre><code>mkdir coastal &amp;&amp; cd coastal\n</code></pre></p> </li> <li> <p>Initialize the project: <pre><code>operator-sdk init --domain coastal.operatorframework.io\n</code></pre></p> </li> <li> <p>Create a new API: <pre><code>operator-sdk create api \\\n    --group coastal.operatorframework.io \\\n    --version v1alpha1 \\\n    --kind Coast \\\n    --resource --controller\n</code></pre></p> </li> </ul>"},{"location":"demos/coast-to-coast-q4-2023/#build-the-extension-and-bundle-images","title":"Build the extension and bundle images","text":"<p>For this demo we are going to build a several different versions of this extension: - <code>v1.0.0-alpha1</code> - <code>v1.0.0</code> - <code>v1.0.1</code> - <code>v1.1.0</code> - <code>v2.0.0</code></p> <p>Initial setup: - Create the <code>manifests/</code> directory for building the plain bundle <pre><code>  mkdir -p manifests\n</code></pre></p> <ul> <li>Create a Dockerfile for the plain bundle image <pre><code>cat &lt;&lt; EOF &gt; plainbundle.Dockerfile\nFROM scratch\nADD manifests /manifests\nEOF\n</code></pre></li> </ul> <p>For each of the versions above, perform the following actions: - Generate the manifests <pre><code>  make generate manifests\n</code></pre></p> <ul> <li> <p>Build the controller image <pre><code>  make docker-build IMG=\"quay.io/operator-framework/coastal:{VERSION}\"\n</code></pre></p> </li> <li> <p>Populate the <code>manifests/</code> directory for building the plain bundle <pre><code>  kustomize build config/default &gt; manifests/manifests.yaml\n</code></pre></p> </li> <li> <p>Build the plain bundle image <pre><code>docker build -t quay.io/operator-framework/coastal-bundle:{VERSION} -f plainbundle.Dockerfile .\n</code></pre></p> </li> <li> <p>Push the controller image and plain bundle image <pre><code>docker push quay.io/operator-framework/coastal:{VERSION} &amp;&amp; \\\ndocker push quay.io/operator-framework/coastal-bundle:{VERSION}\n</code></pre></p> </li> </ul> <p>A handy little script to run all these steps for you: <pre><code>#!/usr/bin/env bash\nset -e\n\nmkdir -p manifests\n\ncat &lt;&lt; EOF &gt; plainbundle.Dockerfile\nFROM scratch\nADD manifests /manifests\nEOF\n\nversions=( v1.0.0-alpha1 v1.0.0 v1.0.1 v1.1.0 v2.0.0 )\nfor version in \"${versions[@]}\"\ndo\n  make generate manifests\n  make docker-build IMG=\"quay.io/operator-framework/coastal:${version}\"\n  mkdir -p manifests\n  kustomize build config/default &gt; manifests/manifests.yaml\n  docker build -t \"quay.io/operator-framework/coastal-bundle:${version}\" -f plainbundle.Dockerfile .\n  docker push \"quay.io/operator-framework/coastal:${version}\"\n  docker push \"quay.io/operator-framework/coastal-bundle:${version}\"\ndone\n</code></pre></p>"},{"location":"demos/coast-to-coast-q4-2023/#create-an-initial-file-based-catalog-fbc-image","title":"Create an initial File-Based Catalog (FBC) Image","text":"<p>Now we need to build and push an initial File-Based Catalog (FBC) image containing our bundles. To help highlight the new polling functionality, we will generate a catalog containing only the <code>v1.0.0-alpha1</code> bundle and we will mimic active development by incrementally updating the catalog image to include more of our bundles.</p> <ul> <li> <p>Create a <code>catalog/</code> directory <pre><code>mkdir catalog\n</code></pre></p> </li> <li> <p>Create a Dockerfile for the catalog image <pre><code>cat &lt;&lt; EOF &gt; catalog.Dockerfile\nFROM scratch\nADD catalog /configs\nLABEL operators.operatorframework.io.index.configs.v1=/configs\nEOF\n</code></pre></p> </li> <li> <p>Create the FBC YAML file <pre><code>cat &lt;&lt; EOF &gt; catalog/index.yaml\nschema: olm.package\nname: coastal\n---\nschema: olm.bundle\nname: coastal.v1.0.0-alpha1\npackage: coastal\nimage: quay.io/operator-framework/coastal-bundle:v1.0.0-alpha1\nproperties:\n  - type: olm.package\n    value:\n      packageName: coastal\n      version: 1.0.0-alpha1\n  - type: olm.bundle.mediatype\n    value: plain+v0\n---\nschema: olm.channel\nname: stable\npackage: coastal\nentries:\n  - name: coastal.v1.0.0-alpha1\nEOF\n</code></pre></p> </li> <li> <p>Build and push the catalog image <pre><code>docker build -t quay.io/operator-framework/coastal-catalog:latest -f catalog.Dockerfile . &amp;&amp; \\\ndocker push quay.io/operator-framework/coastal-catalog:latest\n</code></pre></p> </li> </ul>"},{"location":"demos/coast-to-coast-q4-2023/#create-a-catalog-resource","title":"Create a <code>Catalog</code> Resource","text":"<p>Create a <code>Catalog</code> resource that references the catalog image we built in the previous step and specify a polling interval of 15 seconds. This will make sure that the updates we make to the catalog image are reflected on our cluster relatively quickly.</p> <ul> <li>Create the <code>Catalog</code> resource: <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: catalogd.operatorframework.io/v1alpha1\nkind: Catalog\nmetadata:\n  name: coastal\nspec:\n  source:\n    type: image\n    image:\n      ref: quay.io/operator-framework/coastal-catalog:latest\n      pollInterval: 15s\nEOF\n</code></pre></li> </ul>"},{"location":"demos/coast-to-coast-q4-2023/#only-installupgrade-to-v10z-releases","title":"Only install/upgrade to <code>v1.0.z</code> releases","text":"<p>In this section we are going to create a <code>ClusterExtension</code> resource that attempts to install our extension with a version range of <code>1.0.x</code>. This version range ensures we only install z-stream releases for <code>v1.0</code> excluding pre-release versions.</p> <ul> <li>Create the <code>ClusterExtension</code> resource: <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  name: coastal\nspec:\n  packageName: coastal\n  version: 1.0.x\nEOF\n</code></pre></li> </ul> <p>We should see the <code>ClusterExtension</code> resource eventually has a failed resolution status. Verify this with: <pre><code>kubectl get clusterextension/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"olm.operatorframework.io/v1alpha1\",\"kind\":\"ClusterExtension\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"packageName\":\"coastal\",\"version\":\"1.0.x\"}}\n  creationTimestamp: \"2023-11-27T20:29:18Z\"\n  generation: 1\n  name: coastal\n  resourceVersion: \"2983\"\n  uid: 48d16240-edae-4904-bad8-58137bebcf8a\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Enforce\n  version: 1.0.x\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:29:18Z\"\n    message: installation has not been attempted as resolution failed\n    observedGeneration: 1\n    reason: InstallationStatusUnknown\n    status: Unknown\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:29:18Z\"\n    message: no package \"coastal\" matching version \"1.0.x\" found\n    observedGeneration: 1\n    reason: ResolutionFailed\n    status: \"False\"\n    type: Resolved\n</code></pre> <p>[!NOTE] The above command establishes a watch on the <code>ClusterExtension</code> resource and blocks. Once you are done verifying the resolution status you can exit the command with <code>ctrl+c</code></p>"},{"location":"demos/coast-to-coast-q4-2023/#update-the-fbc-image-to-contain-a-bundle-for-v100","title":"Update the FBC Image to contain a bundle for <code>v1.0.0</code>","text":"<p>To highlight both the polling functionality and the version range constraints, let's add the <code>v1.0.0</code> bundle of our extension to the catalog image we created in the preparation steps and push the changes.</p> <ul> <li> <p>Add the new bundle to the catalog YAML file <pre><code>cat &lt;&lt; EOF &gt;&gt; catalog/index.yaml\n---\nschema: olm.bundle\nname: coastal.v1.0.0\npackage: coastal\nimage: quay.io/operator-framework/coastal-bundle:v1.0.0\nproperties:\n  - type: olm.package\n    value:\n      packageName: coastal\n      version: 1.0.0\n  - type: olm.bundle.mediatype\n    value: plain+v0\nEOF\n</code></pre></p> </li> <li> <p>Using <code>yq</code>, update the channel to include this bundle as an entry <pre><code>yq eval 'select(.schema==\"olm.channel\" and .name == \"stable\").entries += [{\"name\" : \"coastal.v1.0.0\"}]' -i catalog/index.yaml\n</code></pre></p> </li> <li> <p>Build and push the catalog image <pre><code>docker build -t quay.io/operator-framework/coastal-catalog:latest -f catalog.Dockerfile . &amp;&amp; \\\ndocker push quay.io/operator-framework/coastal-catalog:latest\n</code></pre></p> </li> </ul> <p>Shortly, we should see that the <code>Catalog</code> resource updates to have a new resolved reference and the <code>ClusterExtension</code> resource we created previously is successfully installed. </p> <p>Verify this for the <code>ClusterExtension</code> with: <pre><code>kubectl get clusterextension/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"olm.operatorframework.io/v1alpha1\",\"kind\":\"ClusterExtension\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"packageName\":\"coastal\",\"version\":\"1.0.x\"}}\n  creationTimestamp: \"2023-11-27T20:29:18Z\"\n  generation: 1\n  name: coastal\n  resourceVersion: \"3875\"\n  uid: 48d16240-edae-4904-bad8-58137bebcf8a\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Enforce\n  version: 1.0.x\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:34:53Z\"\n    message: installed from \"docker.io/bpalmer/coastal-bundle:v1.0.0\"\n    observedGeneration: 1\n    reason: Success\n    status: \"True\"\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:34:49Z\"\n    message: resolved to \"docker.io/bpalmer/coastal-bundle:v1.0.0\"\n    observedGeneration: 1\n    reason: Success\n    status: \"True\"\n    type: Resolved\n  installedBundleResource: docker.io/bpalmer/coastal-bundle:v1.0.0\n  resolvedBundleResource: docker.io/bpalmer/coastal-bundle:v1.0.0\n</code></pre> <p>and for the <code>Catalog</code> with: <pre><code>kubectl get catalog/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: catalogd.operatorframework.io/v1alpha1\nkind: Catalog\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"catalogd.operatorframework.io/v1alpha1\",\"kind\":\"Catalog\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"source\":{\"image\":{\"pollInterval\":\"15s\",\"ref\":\"docker.io/bpalmer/coastal-catalog:latest\"},\"type\":\"image\"}}}\n  creationTimestamp: \"2023-11-27T20:23:55Z\"\n  finalizers:\n  - catalogd.operatorframework.io/delete-server-cache\n  generation: 1\n  name: coastal\n  resourceVersion: \"4173\"\n  uid: 0bb0ca54-bdfe-4c55-abeb-03b8e3f32374\nspec:\n  source:\n    image:\n      pollInterval: 15s\n      ref: docker.io/bpalmer/coastal-catalog:latest\n    type: image\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:23:57Z\"\n    message: \"\"\n    reason: UnpackSuccessful\n    status: \"True\"\n    type: Unpacked\n  contentURL: http://catalogd-catalogserver.catalogd-system.svc/catalogs/coastal/all.json\n  observedGeneration: 1\n  phase: Unpacked\n  resolvedSource:\n    image:\n      lastPollAttempt: \"2023-11-27T20:36:22Z\"\n      ref: docker.io/bpalmer/coastal-catalog:latest\n      resolvedRef: index.docker.io/bpalmer/coastal-catalog@sha256:b8cb9a4a61f57b59394047cab94f5b4ef1083493809f8180125faedaab17c71d\n    type: image\n</code></pre> <p>Once the <code>ClusterExtension</code> has been successfully installed we can verify that all the resources created are healthy by checking the <code>BundleDeployment</code> resource owned by the <code>ClusterExtension</code> we created. Verify the <code>BundleDeployment</code> has a status condition showing whether or not it is healthy with: <pre><code>kubectl get bundledeployment/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: core.rukpak.io/v1alpha1\nkind: BundleDeployment\nmetadata:\n  creationTimestamp: \"2023-11-27T20:34:49Z\"\n  generation: 2\n  name: coastal\n  ownerReferences:\n  - apiVersion: olm.operatorframework.io/v1alpha1\n    blockOwnerDeletion: true\n    controller: true\n    kind: ClusterExtension\n    name: coastal\n    uid: 48d16240-edae-4904-bad8-58137bebcf8a\n  resourceVersion: \"3935\"\n  uid: 7e487080-15c3-4e56-8789-9a9b516e98b7\nspec:\n  provisionerClassName: core-rukpak-io-plain\n  template:\n    metadata: {}\n    spec:\n      provisionerClassName: core-rukpak-io-plain\n      source:\n        image:\n          ref: docker.io/bpalmer/coastal-bundle:v1.0.0\n        type: image\nstatus:\n  activeBundle: coastal-v725xf\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:34:49Z\"\n    message: Successfully unpacked the coastal-v725xf Bundle\n    reason: UnpackSuccessful\n    status: \"True\"\n    type: HasValidBundle\n  - lastTransitionTime: \"2023-11-27T20:34:53Z\"\n    message: Instantiated bundle coastal-v725xf successfully\n    reason: InstallationSucceeded\n    status: \"True\"\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:35:04Z\"\n    message: BundleDeployment is healthy\n    reason: Healthy\n    status: \"True\"\n    type: Healthy\n  observedGeneration: 2\n</code></pre>"},{"location":"demos/coast-to-coast-q4-2023/#update-the-fbc-image-to-contain-a-bundle-for-v110","title":"Update the FBC Image to contain a bundle for <code>v1.1.0</code>","text":"<p>Let's ensure that adding a bundle with a version of <code>v1.1.0</code> does not trigger an upgrade.</p> <ul> <li> <p>Add the new bundle to the catalog YAML file <pre><code>cat &lt;&lt; EOF &gt;&gt; catalog/index.yaml\n---\nschema: olm.bundle\nname: coastal.v1.1.0\npackage: coastal\nimage: quay.io/operator-framework/coastal-bundle:v1.1.0\nproperties:\n  - type: olm.package\n    value:\n      packageName: coastal\n      version: 1.1.0\n  - type: olm.bundle.mediatype\n    value: plain+v0\nEOF\n</code></pre></p> </li> <li> <p>Using <code>yq</code>, update the channel to include this bundle as an entry <pre><code>yq eval 'select(.schema==\"olm.channel\" and .name == \"stable\").entries += [{\"name\" : \"coastal.v1.1.0\"}]' -i catalog/index.yaml\n</code></pre></p> </li> <li> <p>Build and push the catalog image <pre><code>docker build -t quay.io/operator-framework/coastal-catalog:latest -f catalog.Dockerfile . &amp;&amp; \\\ndocker push quay.io/operator-framework/coastal-catalog:latest\n</code></pre></p> </li> </ul> <p>Similar to the previous procedure, the <code>Catalog</code> updates its resolved reference, but the <code>ClusterExtension</code> resource remains the same and does not  automatically upgrade to <code>v1.1.0</code></p>"},{"location":"demos/coast-to-coast-q4-2023/#update-the-fbc-image-to-contain-a-bundle-for-v101","title":"Update the FBC Image to contain a bundle for <code>v1.0.1</code>","text":"<p>Lets add the <code>v1.0.1</code> bundle to our catalog  and ensure it automatically upgrades within the z-stream.</p> <ul> <li> <p>Add the new bundle to the catalog YAML file <pre><code>cat &lt;&lt; EOF &gt;&gt; catalog/index.yaml\n---\nschema: olm.bundle\nname: coastal.v1.0.1\npackage: coastal\nimage: quay.io/operator-framework/coastal-bundle:v1.0.1\nproperties:\n  - type: olm.package\n    value:\n      packageName: coastal\n      version: 1.0.1\n  - type: olm.bundle.mediatype\n    value: plain+v0\nEOF\n</code></pre></p> </li> <li> <p>Using <code>yq</code>, update the channel to include this bundle as an entry <pre><code>yq eval 'select(.schema==\"olm.channel\" and .name == \"stable\").entries += [{\"name\" : \"coastal.v1.0.1\"}]' -i catalog/index.yaml\n</code></pre></p> </li> <li> <p>Build and push the catalog image <pre><code>docker build -t quay.io/operator-framework/coastal-catalog:latest -f catalog.Dockerfile . &amp;&amp; \\\ndocker push quay.io/operator-framework/coastal-catalog:latest\n</code></pre></p> </li> </ul> <p>Once again, we should see the <code>Catalog</code> update its resolved reference. This time, we expect that the <code>ClusterExtension</code> resource is automatically upgraded to the new <code>v1.0.1</code> bundle we added.</p> Example Catalog <pre><code>apiVersion: catalogd.operatorframework.io/v1alpha1\nkind: Catalog\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"catalogd.operatorframework.io/v1alpha1\",\"kind\":\"Catalog\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"source\":{\"image\":{\"pollInterval\":\"15s\",\"ref\":\"docker.io/bpalmer/coastal-catalog:latest\"},\"type\":\"image\"}}}\n  creationTimestamp: \"2023-11-27T20:23:55Z\"\n  finalizers:\n  - catalogd.operatorframework.io/delete-server-cache\n  generation: 1\n  name: coastal\n  resourceVersion: \"4776\"\n  uid: 0bb0ca54-bdfe-4c55-abeb-03b8e3f32374\nspec:\n  source:\n    image:\n      pollInterval: 15s\n      ref: docker.io/bpalmer/coastal-catalog:latest\n    type: image\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:23:57Z\"\n    message: \"\"\n    reason: UnpackSuccessful\n    status: \"True\"\n    type: Unpacked\n  contentURL: http://catalogd-catalogserver.catalogd-system.svc/catalogs/coastal/all.json\n  observedGeneration: 1\n  phase: Unpacked\n  resolvedSource:\n    image:\n      lastPollAttempt: \"2023-11-27T20:39:45Z\"\n      ref: docker.io/bpalmer/coastal-catalog:latest\n      resolvedRef: index.docker.io/bpalmer/coastal-catalog@sha256:8affa0e6ca81e07bb9d03b934173687f63015d8b36fac3ba3391a942b23cc3ee\n    type: image\n</code></pre> Example ClusterExtension <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"olm.operatorframework.io/v1alpha1\",\"kind\":\"ClusterExtension\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"packageName\":\"coastal\",\"version\":\"1.0.x\"}}\n  creationTimestamp: \"2023-11-27T20:29:18Z\"\n  generation: 1\n  name: coastal\n  resourceVersion: \"4778\"\n  uid: 48d16240-edae-4904-bad8-58137bebcf8a\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Enforce\n  version: 1.0.x\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:34:53Z\"\n    message: installed from \"docker.io/bpalmer/coastal-bundle:v1.0.1\"\n    observedGeneration: 1\n    reason: Success\n    status: \"True\"\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:34:49Z\"\n    message: resolved to \"docker.io/bpalmer/coastal-bundle:v1.0.1\"\n    observedGeneration: 1\n    reason: Success\n    status: \"True\"\n    type: Resolved\n  installedBundleResource: docker.io/bpalmer/coastal-bundle:v1.0.1\n  resolvedBundleResource: docker.io/bpalmer/coastal-bundle:v1.0.1\n</code></pre>"},{"location":"demos/coast-to-coast-q4-2023/#change-version-range-to-pin-installsupgrades-to-v11z-releases","title":"Change version range to pin installs/upgrades to <code>v1.1.z</code> releases","text":"<p>Making changes to the <code>ClusterExtension</code> resource should result in a re-reconciliation of the resource which should result in another resolution loop. To see this, let's update the version range on our <code>ClusterExtension</code> resource to <code>1.1.x</code> with: <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  name: coastal\nspec:\n  packageName: coastal\n  version: 1.1.x\nEOF\n</code></pre></p> <p>After this change has been applied, the <code>ClusterExtension</code> resource is updated and says that we have installed the <code>v1.1.0</code> bundle.</p> <p>You can watch this change happen with: <pre><code>kubectl get clusterextension/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"olm.operatorframework.io/v1alpha1\",\"kind\":\"ClusterExtension\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"packageName\":\"coastal\",\"version\":\"1.1.x\"}}\n  creationTimestamp: \"2023-11-27T20:29:18Z\"\n  generation: 2\n  name: coastal\n  resourceVersion: \"5251\"\n  uid: 48d16240-edae-4904-bad8-58137bebcf8a\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Enforce\n  version: 1.1.x\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:34:53Z\"\n    message: installed from \"docker.io/bpalmer/coastal-bundle:v1.1.0\"\n    observedGeneration: 2\n    reason: Success\n    status: \"True\"\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:34:49Z\"\n    message: resolved to \"docker.io/bpalmer/coastal-bundle:v1.1.0\"\n    observedGeneration: 2\n    reason: Success\n    status: \"True\"\n    type: Resolved\n  installedBundleResource: docker.io/bpalmer/coastal-bundle:v1.1.0\n  resolvedBundleResource: docker.io/bpalmer/coastal-bundle:v1.1.0\n</code></pre>"},{"location":"demos/coast-to-coast-q4-2023/#attempting-a-major-version-upgrade-by-changing-the-version-range","title":"Attempting a major version upgrade by changing the version range","text":"<p>The operator-controller follows semver and prevents automatic upgrades to new major versions when a <code>ClusterExtension</code>'s <code>spec.upgradeConstraintPolicy</code> is set to <code>Enforce</code>. New major versions might have breaking changes and could cause problems for users. Let's add a new major  version of our bundle to the catalog image and update the version range on the <code>ClusterExtension</code>.</p>"},{"location":"demos/coast-to-coast-q4-2023/#update-the-fbc-image-to-contain-a-bundle-for-v200","title":"Update the FBC Image to contain a bundle for <code>v2.0.0</code>","text":"<ul> <li> <p>Add the new bundle to the catalog YAML file <pre><code>cat &lt;&lt; EOF &gt;&gt; catalog/index.yaml\n---\nschema: olm.bundle\nname: coastal.v2.0.0\npackage: coastal\nimage: quay.io/operator-framework/coastal-bundle:v2.0.0\nproperties:\n  - type: olm.package\n    value:\n      packageName: coastal\n      version: 2.0.0\n  - type: olm.bundle.mediatype\n    value: plain+v0\nEOF\n</code></pre></p> </li> <li> <p>Using <code>yq</code>, update the channel to include this bundle as an entry <pre><code>yq eval 'select(.schema==\"olm.channel\" and .name == \"stable\").entries += [{\"name\" : \"coastal.v2.0.0\"}]' -i catalog/index.yaml\n</code></pre></p> </li> <li> <p>Build and push the catalog image <pre><code>docker build -t quay.io/operator-framework/coastal-catalog:latest -f catalog.Dockerfile . &amp;&amp; \\\ndocker push quay.io/operator-framework/coastal-catalog:latest\n</code></pre></p> </li> </ul> <p>The <code>Catalog</code> updates its resolved reference and no changes are applied to the <code>ClusterExtension</code> resource.</p> <p>Updating the <code>ClusterExtension</code> resource's version range will still result in a resolution failure since the version installed is a lower major version than specified by the version range. Try it by running: <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  name: coastal\nspec:\n  packageName: coastal\n  version: 2.0.x\nEOF\n</code></pre></p> <p>Watch for a resolution failure with: <pre><code>kubectl get clusterextension/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"olm.operatorframework.io/v1alpha1\",\"kind\":\"ClusterExtension\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"packageName\":\"coastal\",\"version\":\"2.0.x\"}}\n  creationTimestamp: \"2023-11-27T20:29:18Z\"\n  generation: 3\n  name: coastal\n  resourceVersion: \"6883\"\n  uid: 48d16240-edae-4904-bad8-58137bebcf8a\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Enforce\n  version: 2.0.x\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:50:27Z\"\n    message: installation has not been attempted as resolution is unsatisfiable\n    observedGeneration: 3\n    reason: InstallationStatusUnknown\n    status: Unknown\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:50:27Z\"\n    message: |-\n      constraints not satisfiable:\n      coastal package uniqueness permits at most 1 of coastal-coastal-coastal.v2.0.0, coastal-coastal-coastal.v1.1.0\n      installed package coastal requires at least one of coastal-coastal-coastal.v1.1.0\n      installed package coastal is mandatory\n      required package coastal requires at least one of coastal-coastal-coastal.v2.0.0\n      required package coastal is mandatory\n    observedGeneration: 3\n    reason: ResolutionFailed\n    status: \"False\"\n    type: Resolved\n</code></pre>"},{"location":"demos/coast-to-coast-q4-2023/#to-the-escape-hatch","title":"To the escape hatch!","text":"<p>To tell operator-controller to ignore the semver policies and allow upgrades across major versions, set the <code>ClusterExtension</code>'s <code>spec.upgradeConstraintPolicy</code> to <code>Ignore</code> with: <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  name: coastal\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Ignore\n  version: 2.0.x\nEOF\n</code></pre></p> <p>We should see that eventually the <code>ClusterExtension</code> will resolve and install the <code>v2.0.0</code> bundle we added to the catalog image in the previous step. Watch this happen with: <pre><code>kubectl get clusterextension/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"olm.operatorframework.io/v1alpha1\",\"kind\":\"ClusterExtension\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"packageName\":\"coastal\",\"upgradeConstraintPolicy\":\"Ignore\",\"version\":\"2.0.x\"}}\n  creationTimestamp: \"2023-11-27T20:29:18Z\"\n  generation: 4\n  name: coastal\n  resourceVersion: \"7338\"\n  uid: 48d16240-edae-4904-bad8-58137bebcf8a\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Ignore\n  version: 2.0.x\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:52:58Z\"\n    message: installed from \"docker.io/bpalmer/coastal-bundle:v2.0.0\"\n    observedGeneration: 4\n    reason: Success\n    status: \"True\"\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:52:58Z\"\n    message: resolved to \"docker.io/bpalmer/coastal-bundle:v2.0.0\"\n    observedGeneration: 4\n    reason: Success\n    status: \"True\"\n    type: Resolved\n  installedBundleResource: docker.io/bpalmer/coastal-bundle:v2.0.0\n  resolvedBundleResource: docker.io/bpalmer/coastal-bundle:v2.0.0\n</code></pre>"},{"location":"demos/coast-to-coast-q4-2023/#attempting-to-downgrade-by-changing-the-version-range","title":"Attempting to downgrade by changing the version range","text":"<p>We can disable downgrades by setting the <code>ClusterExtension</code> resource's <code>spec.UpgradeConstraintPolicy</code> field to <code>Enforce</code>. To see this, run: <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  name: coastal\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Enforce\n  version: 1.1.x\nEOF\n</code></pre></p> <p>We should see resolution fail since it is attempting to downgrade. Watch this happen with: <pre><code>kubectl get clusterextension/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"olm.operatorframework.io/v1alpha1\",\"kind\":\"ClusterExtension\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"packageName\":\"coastal\",\"upgradeConstraintPolicy\":\"Enforce\",\"version\":\"1.1.x\"}}\n  creationTimestamp: \"2023-11-27T20:29:18Z\"\n  generation: 5\n  name: coastal\n  resourceVersion: \"7601\"\n  uid: 48d16240-edae-4904-bad8-58137bebcf8a\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Enforce\n  version: 1.1.x\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:53:55Z\"\n    message: installation has not been attempted as resolution is unsatisfiable\n    observedGeneration: 5\n    reason: InstallationStatusUnknown\n    status: Unknown\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:53:55Z\"\n    message: |-\n      constraints not satisfiable:\n      coastal package uniqueness permits at most 1 of coastal-coastal-coastal.v1.1.0, coastal-coastal-coastal.v2.0.0\n      installed package coastal requires at least one of coastal-coastal-coastal.v2.0.0\n      installed package coastal is mandatory\n      required package coastal requires at least one of coastal-coastal-coastal.v1.1.0\n      required package coastal is mandatory\n    observedGeneration: 5\n    reason: ResolutionFailed\n    status: \"False\"\n    type: Resolved\n</code></pre>"},{"location":"demos/coast-to-coast-q4-2023/#back-to-the-escape-hatch","title":"Back to the escape hatch!","text":"<p>To tell operator-controller to ignore the safety mechanisms and downgrade the <code>ClusterExtension</code> version, set the <code>ClusterExtension</code>'s <code>spec.upgradeConstraintPolicy</code> to <code>Ignore</code> with: <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  name: coastal\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Ignore\n  version: 1.1.x\nEOF\n</code></pre></p> <p>We should see that eventually the <code>ClusterExtension</code> will resolve and install the <code>v1.1.0</code> bundle we added to the catalog image in a previous step.  Watch this happen with: <pre><code>kubectl get clusterextension/coastal -o yaml -w\n</code></pre></p> Example <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"olm.operatorframework.io/v1alpha1\",\"kind\":\"ClusterExtension\",\"metadata\":{\"annotations\":{},\"name\":\"coastal\"},\"spec\":{\"packageName\":\"coastal\",\"upgradeConstraintPolicy\":\"Ignore\",\"version\":\"1.1.x\"}}\n  creationTimestamp: \"2023-11-27T20:29:18Z\"\n  generation: 6\n  name: coastal\n  resourceVersion: \"7732\"\n  uid: 48d16240-edae-4904-bad8-58137bebcf8a\nspec:\n  packageName: coastal\n  upgradeConstraintPolicy: Ignore\n  version: 1.1.x\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-27T20:54:38Z\"\n    message: installed from \"docker.io/bpalmer/coastal-bundle:v1.1.0\"\n    observedGeneration: 6\n    reason: Success\n    status: \"True\"\n    type: Installed\n  - lastTransitionTime: \"2023-11-27T20:54:38Z\"\n    message: resolved to \"docker.io/bpalmer/coastal-bundle:v1.1.0\"\n    observedGeneration: 6\n    reason: Success\n    status: \"True\"\n    type: Resolved\n  installedBundleResource: docker.io/bpalmer/coastal-bundle:v1.1.0\n  resolvedBundleResource: docker.io/bpalmer/coastal-bundle:v1.1.0\n</code></pre>"},{"location":"drafts/support-watchNamespaces/","title":"Install Modes and WatchNamespaces in OMLv1","text":"<p>Operator Lifecycle Manager (OLM) operates with cluster-admin privileges, enabling it to grant necessary permissions to the Extensions it deploys. For extensions packaged as <code>RegistryV1</code> bundles, it's the responsibility of the authors to specify supported <code>InstallModes</code> in the ClusterServiceVersion (CSV). InstallModes define the operational scope of the extension within the Kubernetes cluster, particularly in terms of namespace availability. The four recognized InstallModes are as follows:</p> <ol> <li>OwnNamespace: This mode allows the extension to monitor and respond to events within its own deployment namespace.</li> <li>SingleNamespace: In this mode, the extension is set up to observe events in a single, specific namespace other than the one it is deployed in.</li> <li>MultiNamespace: This enables the extension to function across multiple specified namespaces.</li> <li>AllNamespaces: Under this mode, the extension is equipped to monitor events across all namespaces within the cluster.</li> </ol> <p>When creating a cluster extension, users have the option to define a list of <code>watchNamespaces</code>. This list determines the specific namespaces within which they intend the operator to operate. The configuration of <code>watchNamespaces</code> must align with the InstallModes supported by the extension as specified by the bundle author. The supported configurations in the order of preference are as follows:</p> Length of <code>watchNamespaces</code> specified through ClusterExtension Allowed values Supported InstallMode in CSV Description 0 (Empty/Unset) - AllNamespaces Extension monitors all namespaces. - OwnNamespace Supported when <code>AllNamespaces</code> is false. Extension only active in its deployment namespace. 1 (Single Entry) <code>\"\"</code> (Empty String) AllNamespaces Extension monitors all namespaces. Entry equals Install Namespace OwnNamespace Extension watches only its install namespace. Entry is a specific namespace (not the Install Namespace) SingleNamespace Extension monitors a single, specified namespace in the spec. &gt;1 (Multiple Entries) Entries are specific, multiple namespaces MultiNamespace Extension monitors each of the specified multiple namespaces in the spec."},{"location":"drafts/upgrade-support/","title":"Upgrade support","text":"<p>This document explains how OLM 1.0 handles upgrades.</p> <p>OLM 1.0 introduces a simplified UX for package authors and package admins to implicitly define upgrade edges via Semantic Versioning.</p> <p>It also introduces an API to enable independently verified upgrades and downgrades.</p>"},{"location":"drafts/upgrade-support/#upgrade-constraint-semantics","title":"Upgrade constraint semantics","text":"<p>As of operator-controller release 0.8.0, OLM 1.0 supports the following upgrade constraint semantics:</p> <ul> <li>Semantic Versioning (Semver)</li> <li>The <code>replaces</code> directive from the legacy OLM 0 semantics</li> </ul> <p>The Kubernetes manifests in this repo enable Semver support by default. Cluster admins can control which semantics to use by passing one of the following arguments to the <code>manager</code> binary: * <code>--feature-gates=ForceSemverUpgradeConstraints=true</code> - enable Semver * <code>--feature-gates=ForceSemverUpgradeConstraints=false</code> - disable Semver, use legacy semantics</p> <p>For example, to enable Semver update the <code>controller-manager</code> Deployment manifest to include the following argument:</p> <pre><code>- command:\n  - /manager\n  args:\n  - --feature-gates=ForceSemverUpgradeConstraints=true\n  image: controller:latest\n</code></pre> <p>In a future release, it is planned to remove the <code>ForceSemverUpgradeConstraints</code> feature gate and allow package authors to specify upgrade constraint semantics at the catalog level.</p>"},{"location":"drafts/upgrade-support/#upgrades","title":"Upgrades","text":"<p>OLM supports Semver to provide a simplified way for package authors to define compatible upgrades. According to the Semver standard, releases within a major version (e.g. <code>&gt;=1.0.0 &lt;2.0.0</code>) must be compatible. As a result, package authors can publish a new package version following the Semver specification, and OLM assumes compatibility. Package authors do not have to explicitly define upgrade edges in the catalog.</p> <p>[!NOTE] Currently, OLM 1.0 does not support automatic upgrades to the next major version. You must manually verify and perform major version upgrades. For more information about major version upgrades, see Manually verified upgrades and downgrades.</p>"},{"location":"drafts/upgrade-support/#upgrades-within-the-major-version-zero","title":"Upgrades within the major version zero","text":"<p>According to the Semver specification, a major version zero release is for initial development. It is assumed that breaking changes might be introduced at any time. As a result, the following special conditions apply to upgrades within a major version zero release:</p> <ul> <li>You cannot automatically upgrade from one patch version to another when both major and minor versions are <code>0</code>. For example, automatic upgrades within the following version range are not allowed: <code>&gt;= 0.0.1 &lt;0.1.0</code>.</li> <li>You cannot automatically upgrade from one minor version to another minor version within the major version zero. For example, no upgrades from <code>0.1.0</code> to <code>0.2.0</code>. However, you can upgrade from patch versions. For example, upgrades are possible in ranges <code>&gt;= 0.1.0 &lt;0.2.0</code>, <code>&gt;= 0.2.0 &lt;0.3.0</code>, <code>&gt;= 0.3.0 &lt;0.4.0</code>, and so on.</li> </ul> <p>You must verify and perform upgrades manually in cases where automatic upgrades are blocked.</p>"},{"location":"drafts/upgrade-support/#manually-verified-upgrades-and-downgrades","title":"Manually verified upgrades and downgrades","text":"<p>Warning: If you want to force an upgrade manually, you must thoroughly verify the outcome before applying any changes to production workloads. Failure to test and verify the upgrade might lead to catastrophic consequences such as data loss.</p> <p>As a package admin, if you must upgrade or downgrade to version that might be incompatible with the currently installed version, you can set the <code>.spec.upgradeConstraintPolicy</code> field to <code>Ignore</code> on the relevant <code>ClusterExtension</code> resource.</p> <p>If you set the field to <code>Ignore</code>, no upgrade constraints are set on the package. As a result, you can change the version to any version available in the catalogs for a given package.</p> <p>Example <code>ClusterExtension</code> with <code>.spec.upgradeConstraintPolicy</code> field set to <code>Ignore</code>:</p> <pre><code>apiVersion: olm.operatorframework.io/v1alpha1\nkind: ClusterExtension\nmetadata:\n  name: extension-sample\nspec:\n  packageName: argocd-operator\n  version: 0.6.0\n  upgradeConstraintPolicy: Ignore\n</code></pre>"},{"location":"drafts/version-ranges/","title":"Extension version ranges","text":"<p>This document explains how to specify a version range to install or update an extension with OLM 1.0.</p> <p>You define a version range in a ClusterExtension's custom resource (CR) file.</p>"},{"location":"drafts/version-ranges/#specifying-a-version-range-in-the-cr","title":"Specifying a version range in the CR","text":"<p>If you specify a version range in the ClusterExtension's CR, OLM 1.0 installs or updates the latest version of the extension that can be resolved within the version range. The resolved version is the latest version of the extension that satisfies the dependencies and constraints of the extension and the environment. Extension updates within the specified range are automatically installed if they can be resolved successfully. Updates are not installed if they are outside of the specified range or if they cannot be resolved successfully.</p> <p>For more information about dependency and constraint resolution in OLM 1.0, see the Deppy introduction</p>"},{"location":"drafts/version-ranges/#comparisons","title":"Comparisons","text":"<p>You define a version range by adding a comparison string to the <code>spec.version</code> field. A comparison string is composed of a list of comma or space separated values and one or more comparison operators. You can add an additional comparison string by including an OR (<code>||</code>) operator between the strings.</p>"},{"location":"drafts/version-ranges/#basic-comparisons","title":"Basic comparisons","text":"Operator Definition <code>=</code> equal (not aliased to an operator) <code>!=</code> not equal <code>&gt;</code> greater than <code>&lt;</code> less than <code>&gt;=</code> greater than or equal to <code>&lt;=</code> less than or equal to"},{"location":"drafts/version-ranges/#range-comparisons","title":"Range comparisons","text":"<p>To specify a version range, use a range comparison similar to the following example:</p> <pre><code>version: &gt;=3.0, &lt;3.6\n</code></pre>"},{"location":"drafts/version-ranges/#wildcards-in-comparisons","title":"Wildcards in comparisons","text":"<p>You can use the <code>x</code>, <code>X</code>, and <code>*</code> characters as wildcard characters in all comparison operations. If you use a wildcard character with the <code>=</code> operator, you define a patch level comparision. This is equivalent to making a tilde range comparison.</p> <p>Example comparisons with wildcard characters | Comparison | Equivalent          | |------------|---------------------| | <code>1.2.x</code>    | <code>&gt;= 1.2.0, &lt; 1.3.0</code> | | <code>&gt;= 1.2.x</code> | <code>&gt;= 1.2.0</code>          | | <code>&lt;= 2.x</code>   | <code>&lt; 3</code>               | | <code>*</code>        | <code>&gt;= 0.0.0</code>          |</p>"},{"location":"drafts/version-ranges/#patch-release-or-tilde-range-comparison","title":"Patch release or tilde (<code>~</code>) range comparison","text":"<p>You can use the tilde (<code>~</code>) operator to make patch release comparisons. This is useful when you want to specify a minor version up to the next major version.</p> <p>Example patch release comparisons | Comparison | Equivalent          | |------------|---------------------| | <code>~1.2.3</code>   | <code>&gt;= 1.2.3, &lt; 1.3.0</code> | | <code>~1</code>       | <code>&gt;= 1, &lt;2</code>          | | <code>~2.3</code>     | <code>&gt;= 2.3, &lt; 2.4</code>     | | <code>~1.2.x</code>   | <code>&gt;= 1.2.0, &lt; 1.3.0</code> | | <code>~1.x</code>     | <code>&gt;= 1, &lt; 2</code>         |</p>"},{"location":"drafts/version-ranges/#major-release-or-caret-range-comparisons","title":"Major release or caret (<code>^</code>) range comparisons","text":"<p>You can use the caret (<code>^</code>) operator to make major release comparisons after a stable, <code>1.0.0</code>, version is published. If you make a major release comparison before a stable version is published, minor versions define the API stability level.</p> <p>Example major release comparisons</p> Comparison Equivalent <code>^1.2.3</code> <code>&gt;= 1.2.3, &lt; 2.0.0``&gt;= 1.2.3, &lt; 2.0.0</code> <code>^1.2.x</code> <code>&gt;= 1.2.0, &lt; 2.0.0</code> <code>^2.3</code> <code>&gt;= 2.3, &lt; 3</code> <code>^2.x</code> <code>&gt;= 2.0.0, &lt; 3</code> <code>^0.2.3</code> <code>&gt;=0.2.3 &lt;0.3.0</code> <code>^0.2</code> <code>&gt;=0.2.0 &lt;0.3.0</code> <code>^0.0.3</code> <code>&gt;=0.0.3 &lt;0.0.4</code> <code>^0.0</code> <code>&gt;=0.0.0 &lt;0.1.0</code> <code>^0</code> <code>&gt;=0.0.0 &lt;1.0.0</code>"},{"location":"refs/catalog-queries/","title":"Catalog queries","text":"<p>You can use the <code>curl</code> command with <code>jq</code> to query catalogs that are installed on your cluster.</p> Query syntax<pre><code>$ curl http://localhost:8080/catalogs/operatorhubio/all.json | &lt;query&gt;\n</code></pre>"},{"location":"refs/catalog-queries/#package-queries","title":"Package queries","text":"Available packages in a catalog <code>jq -s '.[] | select( .schema == \"olm.package\")</code> Packages that support <code>AllNamespaces</code> install mode and do not use webhooks <p><code>jq -c 'select(.schema == \"olm.bundle\") | {\"package\":.package, \"version\":.properties[] | select(.type == \"olm.bundle.object\").value.data |  @base64d | fromjson | select(.kind == \"ClusterServiceVersion\" and (.spec.installModes[] | select(.type == \"AllNamespaces\" and .supported == true) != null) and .spec.webhookdefinitions == null).spec.version}'</code></p> Package metadata <code>jq -s '.[] | select( .schema == \"olm.package\") | select( .name == \"&lt;package_name&gt;\")'</code> Catalog blobs in a package <code>jq -s '.[] | select( .package == \"&lt;package_name&gt;\")'</code>"},{"location":"refs/catalog-queries/#channel-queries","title":"Channel queries","text":"Channels in a package <code>jq -s '.[] | select( .schema == \"olm.channel\" ) | select( .package == \"&lt;package_name&gt;\") | .name'</code> Versions in a channel <code>jq -s '.[] | select( .package == \"&lt;package_name&gt;\" ) | select( .schema == \"olm.channel\" ) | select( .name == \"&lt;channel_name&gt;\" ) | .entries | .[] | .name'</code> Latest version in a channel and upgrade path <code>jq -s '.[] | select( .schema == \"olm.channel\" ) | select ( .name == \"&lt;channel&gt;\") | select( .package == \"&lt;package_name&gt;\")'</code>"},{"location":"refs/catalog-queries/#bundle-queries","title":"Bundle queries","text":"Bundles in a package <code>jq -s '.[] | select( .schema == \"olm.bundle\" ) | select( .package == \"&lt;package_name&gt;\") | .name'</code> Bundle dependencies and available APIs <code>jq -s '.[] | select( .schema == \"olm.bundle\" ) | select ( .name == \"&lt;bundle_name&gt;\") | select( .package == \"&lt;package_name&gt;\")'</code>"}]}